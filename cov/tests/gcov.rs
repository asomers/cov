//! Test against output of GCOVR and LCOV.
//!
//! This test program will generate a report for `test-data/*/x.{gcno,gcda}`, and compare against `test-data/*/x.json`.
//! It is considered failure if the report differs.
//!
//! The GCNO and GCDA files, along with GCOVR and LCOV output can be regenerated by running:
//!
//! ```sh
//! cd test-data/
//! ./rebuild.py clean
//! ./rebuild.py
//! ```
//!
//! Note that the GCNO and GCDA files will differ because gcc uses timestamp to differentiate between builds.
//!
//! The JSON files are created manually, and must be manually compared against GCOVR and LCOV to see if the output makes
//! sense.
//!
//! ### Running `rebuild.py`
//!
//! `rebuild.py` primarily runs on the author's machine, so it is highly non-portable at the moment. To run the program,
//! you will need the following executing in `$PATH`:
//!
//! | Executable | Component             |
//! |-----------:|:----------------------|
//! | `python3`  | Python 3.5+           |
//! | `g++-7`    | GCC 7.1               |
//! | `gcov-7`   | GCC 7.1               |
//! | `clang++`  | clang 3.4+            |
//! | `gcov`     | LLVM 3.4+ or GCC 4.6- |
//! | `rustc`    | Rust nightly          |
//! | `lcov`     | LCOV 1.13+            |
//! | `genhtml`  | LCOV 1.13+            |
//! | `gcovr`    | GCOVR 3.3+            |
//!
//! ### Creating a new test
//!
//! 1. Write the new source code in `test-data/src`. Must be a single file, of the form `filename.cpp` or `filename.rs`.
//! 2. Create the folder `test-data/filename.clang/`, `test-data/filename.gcc7/` or `test-data/filename.rustc/`.
//! 3. Run `rebuild.py` (no need to clean)
//! 4. Fill in `test-data/filename.*/x.json`.
//! 5. Run `cargo test` and update the JSON file or the code.


extern crate cov;
extern crate diff;
extern crate serde_json;
extern crate termcolor;

use cov::*;
use serde_json::{Value, from_reader, to_value, to_string_pretty};
use termcolor::{Color, ColorChoice, ColorSpec, StandardStream, WriteColor};

use std::env::args_os;
use std::ffi::OsStr;
use std::fs::{File, read_dir};
use std::io::{self, Write};
use std::path::Path;
use std::process::exit;

fn main() {
    run().expect("IO");
}

fn run() -> io::Result<()> {
    let allowed_extensions = [OsStr::new("gcc7"), OsStr::new("clang"), OsStr::new("rustc")];
    let mut failed_tests = 0;

    let stdout = StandardStream::stdout(ColorChoice::Auto);
    let mut lock = stdout.lock();

    let filter = args_os().nth(1);

    for entry in read_dir("test-data")? {
        let entry = entry?;
        let path = entry.path();
        if let Some(extension) = path.extension() {
            if allowed_extensions.contains(&extension) && entry.file_type()?.is_dir() {
                write!(lock, "test {} ... ", path.display())?;
                lock.flush()?;
                if filter.is_some() && path.file_name() != filter.as_ref().map(|x| &**x) {
                    lock.set_color(ColorSpec::new().set_fg(Some(Color::Yellow)))?;
                    writeln!(lock, "ignored")?;
                    lock.reset()?;
                } else if !print_test_result(&mut lock, test(&path))? {
                    failed_tests += 1;
                }
            }
        }
    }

    if failed_tests != 0 {
        writeln!(lock, "\ntest result: {} failed.\n", failed_tests)?;
        exit(101);
    } else {
        writeln!(lock, "\ntest result: ok.\n")?;
    }

    Ok(())
}

/// Generates a report, and compare with the expected report. Returns both reports a JSON values.
fn test(path: &Path) -> Result<(Value, Value)> {
    let mut interner = Interner::new();
    let mut graph = Graph::new();

    let gcno_path = path.join("x.gcno");
    graph.merge(Gcov::open(&gcno_path, &mut interner)?)?;

    let mut gcda_path = gcno_path;
    gcda_path.set_extension("gcda");
    graph.merge(Gcov::open(&gcda_path, &mut interner)?)?;

    graph.analyze();
    let report = graph.report();
    let actual_report = to_value(report.with_interner(&interner))?;

    let mut report_path = gcda_path;
    report_path.set_extension("json");
    let expected_report = from_reader(File::open(report_path)?)?;

    Ok((actual_report, expected_report))
}

fn print_test_result<W: Write + WriteColor>(mut lock: W, result: Result<(Value, Value)>) -> io::Result<bool> {
    Ok(match result {
        Ok((actual_report, expected_report)) => {
            let success = actual_report == expected_report;
            if success {
                lock.set_color(ColorSpec::new().set_fg(Some(Color::Green)))?;
                writeln!(lock, "ok")?;
            } else {
                lock.set_color(ColorSpec::new().set_fg(Some(Color::Red)))?;
                writeln!(lock, "FAILED")?;
                let actual_report = to_string_pretty(&actual_report).expect("JSON");
                let expected_report = to_string_pretty(&expected_report).expect("JSON");
                for d in diff::lines(&actual_report, &expected_report) {
                    let (color, prefix, line) = match d {
                        diff::Result::Left(line) => (Color::Green, '+', line),
                        diff::Result::Both(line, _) => (Color::White, ' ', line),
                        diff::Result::Right(line) => (Color::Red, '-', line),
                    };
                    lock.set_color(ColorSpec::new().set_fg(Some(color)))?;
                    writeln!(lock, "{} {}", prefix, line)?;
                }
                writeln!(lock)?;
            }
            lock.reset()?;
            success
        },
        Err(e) => {
            lock.set_color(ColorSpec::new().set_fg(Some(Color::Magenta)))?;
            writeln!(lock, "ERRORED")?;
            lock.set_color(ColorSpec::new().set_fg(Some(Color::Red)).set_intense(true).set_bold(true))?;
            write!(lock, "error: ")?;
            lock.reset()?;
            writeln!(lock, "{}\n", e)?;
            false
        },
    })
}
